{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Combining Pandas and SQL for Data Profiling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMrmaViO0EGj+ZJI4XgflLD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kowshiksarker/Python-SQL/blob/main/Combining_Pandas_and_SQL_for_Data_Profiling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-8Hm7Bj9PiB"
      },
      "source": [
        "# Lets import the required libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.datasets import load_iris #loading a sample inbuilt dataset for demo"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vozvCtIa9_56"
      },
      "source": [
        "# installing 'pandasql' library -> https://pypi.org/project/pandasql/\n",
        "!pip install pandasql"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJDrVewb-N-L"
      },
      "source": [
        "# importing pandasql and creating a default function that can be used across the notebook for quering any dataframe\n",
        "from pandasql import sqldf\n",
        "pysqldf = lambda q: sqldf(q, globals())"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZrbzWaB-Ywe"
      },
      "source": [
        "# loading iris dataset into a dataframe and transforming the column names as per the sql standard (removing sapces and special characters)\n",
        "iris = load_iris()\n",
        "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "iris_df['species'] = pd.Categorical.from_codes(iris.target, iris.target_names)\n",
        "iris_df.columns = [re.sub(\"[() ]\", \"\", col) for col in iris_df.columns]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1rBh3eT-qzX"
      },
      "source": [
        "iris_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pt2GzzG-_11D"
      },
      "source": [
        "# Now its time to query the dataframe using pandasql\n",
        "species_count=pysqldf(\"\"\" SELECT species,COUNT(*) from iris_df group by species \"\"\")\n",
        "print(species_count)\n",
        "print(type(species_count))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GiC8x1JAjB5"
      },
      "source": [
        "aggr_data=pysqldf(\"\"\" select species,avg(sepallengthcm) as avg_sepallength,avg(sepalwidthcm) as avg_sepalwidth from iris_df group by species \"\"\")\n",
        "aggr_data"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}